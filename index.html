<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Stream Output Simulator</title>
    <div id="loading" style="position: fixed; top: 0; left: 0; right: 0; background: #ffeb3b; color: black; text-align: center; padding: 10px; z-index: 1000;">
        正在加载模型，请稍候...（首次加载可能需要一些时间）
    </div>
    <script src="https://unpkg.com/@xenova/transformers"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 20px auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .input-group {
            margin-bottom: 15px;
        }
        textarea {
            width: 100%;
            height: 100px;
            margin-bottom: 10px;
            padding: 8px;
            border: 1px solid #ddd;
            border-radius: 4px;
            resize: vertical;
        }
        .controls {
            margin-bottom: 20px;
            display: flex;
            gap: 20px;
            align-items: center;
        }
        input[type="number"] {
            width: 100px;
            padding: 5px;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        button {
            background-color: #4CAF50;
            color: white;
            padding: 10px 20px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }
        button:hover {
            background-color: #45a049;
        }
        #output {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 4px;
            height: 200px;
            overflow-y: auto;
            line-height: 1.8;
            border: 1px solid #ddd;
            font-family: monospace;
            scroll-behavior: smooth;
        }
        .token-info {
            margin-top: 10px;
            color: #666;
        }
        .loading {
            color: #666;
            font-style: italic;
        }
        .token {
            display: inline-block;
            background-color: #e9ecef;
            border: 1px solid #dee2e6;
            border-radius: 3px;
            padding: 0 4px;
            margin: 0 2px;
            font-family: monospace;
            font-size: 14px;
            color: #495057;
        }
        .token:hover {
            background-color: #dee2e6;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>LLM Stream Output Simulator</h1>
        
        <div class="input-group">
            <label for="input-text">输入要显示的文本：</label>
            <textarea id="input-text" placeholder="请输入要流式显示的文本..."></textarea>
        </div>

        <div class="controls">
            <div>
                <label for="interval">Token间隔时间（毫秒）：</label>
                <input type="number" id="interval" value="50" min="10" max="1000">
            </div>
            <div>
                <label for="initial-delay">初始等待时间（秒）：</label>
                <input type="number" id="initial-delay" value="3" min="0" max="10">
            </div>
            <div class="token-info">
                Token数量：<span id="token-count">0</span>
            </div>
        </div>

        <button onclick="startStreaming()">开始流式输出</button>

        <h3>输出结果：</h3>
        <div id="output"></div>
    </div>

    <script>
        let isStreaming = false;
        let cachedTokens = null;
        let tokenizer = null;

        async function initTokenizer() {
            try {
                const errorDiv = document.getElementById('error-message');
                if (errorDiv) {
                    errorDiv.style.display = 'none';
                }

                const { pipeline, AutoTokenizer } = await import('https://cdn.jsdelivr.net/npm/@xenova/transformers@2.15.1/+esm');
                
                pipeline.config = {
                    cache_dir: './models',
                    local_files_only: false
                };

                tokenizer = await AutoTokenizer.from_pretrained('gpt2', {
                    quantized: false,
                    progress_callback: function(progress) {
                        const loadingDiv = document.getElementById('loading');
                        if (loadingDiv) {
                            loadingDiv.textContent = `正在加载模型...${Math.round(progress * 100)}%`;
                        }
                    }
                });
                
                console.log('Tokenizer loaded successfully');
                
                const loadingDiv = document.getElementById('loading');
                if (loadingDiv) {
                    loadingDiv.style.display = 'none';
                }
            } catch (error) {
                console.error('Error loading tokenizer:', error);
                const errorHtml = `
                    <div id="error-message" style="position: fixed; top: 0; left: 0; right: 0; background: #ff5252; color: white; text-align: center; padding: 10px; z-index: 1000;">
                        加载模型失败: ${error.message}
                        <button onclick="retryInitTokenizer()" style="margin-left: 10px; padding: 5px 10px; border: none; background: white; color: #ff5252; border-radius: 4px; cursor: pointer;">
                            重试
                        </button>
                    </div>
                `;
                document.body.insertAdjacentHTML('afterbegin', errorHtml);
            }
        }

        async function retryInitTokenizer() {
            const loadingDiv = document.getElementById('loading');
            if (loadingDiv) {
                loadingDiv.style.display = 'block';
            }
            await initTokenizer();
        }

        initTokenizer();

        function sleep(ms) {
            return new Promise(resolve => setTimeout(resolve, ms));
        }

        async function getTokens(text) {
            try {
                console.log('开始请求tokenize接口...');
                // 使用 Vercel 部署的 API 地址
                const response = await fetch('https://llmstreamsimulator.vercel.app/api/tokenize', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ text }),
                });
                
                console.log('收到响应:', response.status);
                if (!response.ok) {
                    throw new Error(`API请求失败，状态码: ${response.status}`);
                }

                const data = await response.json();
                console.log('解析响应数据:', data);
                if (data.error) {
                    throw new Error(`服务器错误: ${data.error}`);
                }
                return data.tokens;
            } catch (error) {
                console.error('获取token失败:', error);
                throw error;
            }
        }

        async function updateTokenCount() {
            const text = document.getElementById('input-text').value;
            const countSpan = document.getElementById('token-count');
            
            if (!text) {
                countSpan.textContent = '0';
                cachedTokens = null;
                return;
            }

            countSpan.textContent = '计算中...';
            
            try {
                const tokens = await getTokens(text);
                cachedTokens = tokens;
                countSpan.textContent = tokens.length;
            } catch (error) {
                console.error('Token count error:', error);
                countSpan.textContent = '错误';
                cachedTokens = null;
                alert(error.message);
            }
        }

        async function startStreaming() {
            if (isStreaming) return;
            
            const inputText = document.getElementById('input-text').value;
            const interval = parseInt(document.getElementById('interval').value);
            const initialDelay = parseInt(document.getElementById('initial-delay').value) * 1000;
            const outputDiv = document.getElementById('output');
            
            if (!inputText) {
                alert('请输入要显示的文本！');
                return;
            }

            if (!tokenizer) {
                alert('Tokenizer还未加载完成，请稍候...');
                return;
            }

            isStreaming = true;
            outputDiv.textContent = '准备开始...';
            
            try {
                await sleep(initialDelay);
                outputDiv.innerHTML = '';
                
                const tokens = cachedTokens || await getTokens(inputText);
                
                for (let token of tokens) {
                    const tokenSpan = document.createElement('span');
                    tokenSpan.className = 'token';
                    tokenSpan.textContent = token;
                    outputDiv.appendChild(tokenSpan);
                    outputDiv.scrollTop = outputDiv.scrollHeight;
                    await sleep(interval);
                }
            } catch (error) {
                console.error('Error during streaming:', error);
                alert('处理文本时发生错误: ' + error.message);
            } finally {
                isStreaming = false;
            }
        }

        function debounce(func, wait) {
            let timeout;
            return function executedFunction(...args) {
                const later = () => {
                    clearTimeout(timeout);
                    func(...args);
                };
                clearTimeout(timeout);
                timeout = setTimeout(later, wait);
            };
        }

        document.getElementById('input-text').addEventListener('input', debounce(updateTokenCount, 500));
    </script>
</body>
</html>
